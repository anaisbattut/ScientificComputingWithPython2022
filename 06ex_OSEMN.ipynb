{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000000000000000e+00\n",
      "1.000000000000000000e+00\n",
      "2.000000000000000000e+00\n",
      "3.000000000000000000e+00\n",
      "4.000000000000000000e+00\n",
      "5.000000000000000000e+00\n",
      "6.000000000000000000e+00\n",
      "7.000000000000000000e+00\n",
      "8.000000000000000000e+00\n",
      "9.000000000000000000e+00\n",
      "\n",
      "\n",
      "3.84e+00 3.88e+00 5.80e+00 6.35e-01 9.34e+00\n",
      "5.16e+00 4.14e+00 3.99e-01 4.55e+00 6.33e+00\n",
      "8.67e+00 8.62e+00 6.40e+00 2.42e+00 7.70e+00\n",
      "6.37e+00 3.20e+00 3.41e+00 6.04e-01 3.79e+00\n",
      "9.79e-01 5.01e+00 2.61e+00 3.67e+00 9.08e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as npr\n",
    "import csv\n",
    "\n",
    "#text file name\n",
    "file_name1 = './data/data_int.txt'\n",
    "file_name2 = './data/data_float.txt'\n",
    "\n",
    "#list of integer numbers\n",
    "list_int = np.arange(10)\n",
    "#save it in a .txt file\n",
    "np.savetxt(file_name1, list_int)\n",
    "#read it with the cat command\n",
    "!cat data/data_int.txt\n",
    "\n",
    "#a matrix of 5x5 floats\n",
    "a =  npr.uniform(size=(5,5), low = 0, high = 10)\n",
    "#save it in a .txt file\n",
    "np.savetxt(file_name2, a, fmt='%.2e')\n",
    "print(\"\\n\")\n",
    "#read it with the command cat\n",
    "!cat data/data_float.txt\n",
    "\n",
    "#we load the previous file\n",
    "with open(file_name2, 'r') as  in_file, open('./data/data_float.csv', 'w') as out_file:\n",
    "    #we remove the leading and the trailing characters\n",
    "    stripped = [line.strip() for line in in_file]\n",
    "    stripped_bis = []\n",
    "    # separating values belonging to a same line by ';' whereas ' ' (csv format)\n",
    "    for s in stripped:\n",
    "        s = s.replace(' ',';')\n",
    "        stripped_bis.append(s)\n",
    "    lines = (line.split(\",\") for line in stripped_bis if line)\n",
    "    #we write the information in a csv file\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerows(lines)   \n",
    "\n",
    "#The easy way to do it but not by hands\n",
    "#np.savetxt('./data/data_float.csv', a, fmt='%.2e', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load the file user_data.json\n",
    "#!wget https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json -P data/\n",
    "\n",
    "#import json #import the JSON module\n",
    "#data = json.load(open('data/user_data.json'))\n",
    "#filter_json = [x for x in data if x['CreditCardType'] == 'American Express']\n",
    "\n",
    "df = pd.read_json('data/user_data.json')\n",
    "df = df.loc[df['CreditCardType'] == 'American Express']\n",
    "df.to_csv('./data/user_data.csv', index= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"cap-shape\":{\r\n",
      "        \"0\":3.2661596958,\r\n",
      "        \"1\":3.4361593463\r\n",
      "    },\r\n",
      "    \"cap-surface\":{\r\n",
      "        \"0\":1.6159695817,\r\n",
      "        \"1\":2.0551583248\r\n",
      "    },\r\n",
      "    \"cap-color\":{\r\n",
      "        \"0\":4.5817490494,\r\n",
      "        \"1\":4.4218590398\r\n",
      "    },\r\n",
      "    \"bruises\":{\r\n",
      "        \"0\":0.6539923954,\r\n",
      "        \"1\":0.1593462717\r\n",
      "    },\r\n",
      "    \"odor\":{\r\n",
      "        \"0\":4.3346007605,\r\n",
      "        \"1\":3.9407558733\r\n",
      "    },\r\n",
      "    \"gill-attachment\":{\r\n",
      "        \"0\":0.9543726236,\r\n",
      "        \"1\":0.9954034729\r\n",
      "    },\r\n",
      "    \"gill-spacing\":{\r\n",
      "        \"0\":0.2851711027,\r\n",
      "        \"1\":0.0286006129\r\n",
      "    },\r\n",
      "    \"gill-size\":{\r\n",
      "        \"0\":0.0684410646,\r\n",
      "        \"1\":0.5679264556\r\n",
      "    },\r\n",
      "    \"gill-color\":{\r\n",
      "        \"0\":6.6226235741,\r\n",
      "        \"1\":2.8636363636\r\n",
      "    },\r\n",
      "    \"stalk-shape\":{\r\n",
      "        \"0\":0.6159695817,\r\n",
      "        \"1\":0.5148110317\r\n",
      "    },\r\n",
      "    \"stalk-root\":{\r\n",
      "        \"0\":1.4980988593,\r\n",
      "        \"1\":0.6925434116\r\n",
      "    },\r\n",
      "    \"stalk-surface-above-ring\":{\r\n",
      "        \"0\":1.7756653992,\r\n",
      "        \"1\":1.3595505618\r\n",
      "    },\r\n",
      "    \"stalk-surface-below-ring\":{\r\n",
      "        \"0\":1.7984790875,\r\n",
      "        \"1\":1.3942798774\r\n",
      "    },\r\n",
      "    \"stalk-color-above-ring\":{\r\n",
      "        \"0\":6.0988593156,\r\n",
      "        \"1\":5.5127681307\r\n",
      "    },\r\n",
      "    \"stalk-color-below-ring\":{\r\n",
      "        \"0\":6.0646387833,\r\n",
      "        \"1\":5.5045965271\r\n",
      "    },\r\n",
      "    \"veil-type\":{\r\n",
      "        \"0\":0.0,\r\n",
      "        \"1\":0.0\r\n",
      "    },\r\n",
      "    \"veil-color\":{\r\n",
      "        \"0\":1.9315589354,\r\n",
      "        \"1\":2.0020429009\r\n",
      "    },\r\n",
      "    \"ring-number\":{\r\n",
      "        \"0\":1.1254752852,\r\n",
      "        \"1\":1.0091930541\r\n",
      "    },\r\n",
      "    \"ring-type\":{\r\n",
      "        \"0\":3.0076045627,\r\n",
      "        \"1\":1.5229826353\r\n",
      "    },\r\n",
      "    \"spore-print-color\":{\r\n",
      "        \"0\":3.2015209125,\r\n",
      "        \"1\":4.0214504597\r\n",
      "    },\r\n",
      "    \"population\":{\r\n",
      "        \"0\":3.283269962,\r\n",
      "        \"1\":4.0316649642\r\n",
      "    },\r\n",
      "    \"habitat\":{\r\n",
      "        \"0\":1.1482889734,\r\n",
      "        \"1\":1.8958120531\r\n",
      "    }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv -P data/\n",
    "df = pd.read_csv('data/mushrooms_categorized.csv')\n",
    "df_average = df.groupby(['class'])[df.columns.values[1:]].mean()\n",
    "df_average.to_json('data/mushrooms_categorized.json',indent=4)\n",
    "\n",
    "!cat data/mushrooms_categorized.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "16\n",
      "32\n",
      "48\n",
      "64\n",
      "80\n",
      "96\n",
      "112\n",
      "128\n",
      "144\n",
      "160\n",
      "176\n",
      "192\n",
      "208\n",
      "224\n",
      "240\n",
      "256\n",
      "272\n",
      "288\n",
      "304\n",
      "320\n",
      "336\n",
      "352\n",
      "368\n",
      "384\n",
      "400\n",
      "416\n",
      "432\n",
      "448\n",
      "464\n",
      "480\n",
      "496\n",
      "512\n",
      "528\n",
      "544\n",
      "560\n",
      "576\n",
      "592\n",
      "608\n",
      "624\n",
      "640\n",
      "656\n",
      "672\n",
      "688\n",
      "704\n",
      "720\n",
      "736\n",
      "752\n",
      "768\n",
      "784\n",
      "800\n",
      "816\n",
      "832\n",
      "848\n",
      "864\n",
      "880\n",
      "896\n",
      "912\n",
      "928\n",
      "944\n",
      "960\n",
      "976\n",
      "992\n",
      "1008\n",
      "1024\n",
      "1040\n",
      "1056\n",
      "1072\n",
      "1088\n",
      "1104\n",
      "1120\n",
      "1136\n",
      "1152\n",
      "1168\n",
      "1184\n",
      "1200\n",
      "1216\n",
      "1232\n",
      "1248\n",
      "1264\n",
      "1280\n",
      "1296\n",
      "1312\n",
      "1328\n",
      "1344\n",
      "1360\n",
      "1376\n",
      "1392\n",
      "1408\n",
      "1424\n",
      "1440\n",
      "1456\n",
      "1472\n",
      "1488\n",
      "1504\n",
      "1520\n",
      "1536\n",
      "1552\n",
      "1568\n",
      "1584\n",
      "1600\n",
      "1616\n",
      "1632\n",
      "1648\n",
      "1664\n",
      "1680\n",
      "1696\n",
      "1712\n",
      "1728\n",
      "1744\n",
      "1760\n",
      "1776\n",
      "1792\n",
      "1808\n",
      "1824\n",
      "1840\n",
      "1856\n",
      "1872\n",
      "1888\n",
      "1904\n",
      "1920\n",
      "1936\n",
      "1952\n",
      "1968\n",
      "1984\n",
      "2000\n",
      "2016\n",
      "2032\n",
      "2048\n",
      "2064\n",
      "2080\n",
      "2096\n",
      "2112\n",
      "2128\n",
      "2144\n",
      "2160\n",
      "2176\n",
      "2192\n",
      "2208\n",
      "2224\n",
      "2240\n",
      "2256\n",
      "2272\n",
      "2288\n",
      "2304\n",
      "2320\n",
      "2336\n",
      "2352\n",
      "2368\n",
      "2384\n",
      "2400\n",
      "2416\n",
      "2432\n",
      "2448\n",
      "2464\n",
      "2480\n",
      "2496\n",
      "2512\n",
      "2528\n",
      "2544\n",
      "2560\n",
      "2576\n",
      "2592\n",
      "2608\n",
      "2624\n",
      "2640\n",
      "2656\n",
      "2672\n",
      "2688\n",
      "2704\n",
      "2720\n",
      "2736\n",
      "2752\n",
      "2768\n",
      "2784\n",
      "2800\n",
      "2816\n",
      "2832\n",
      "2848\n",
      "2864\n",
      "2880\n",
      "2896\n",
      "2912\n",
      "2928\n",
      "2944\n",
      "2960\n",
      "2976\n",
      "2992\n",
      "3008\n",
      "3024\n",
      "3040\n",
      "3056\n",
      "3072\n",
      "3088\n",
      "3104\n",
      "3120\n",
      "3136\n",
      "3152\n",
      "3168\n",
      "3184\n",
      "3200\n",
      "3216\n",
      "3232\n",
      "3248\n",
      "3264\n",
      "3280\n",
      "3296\n",
      "3312\n",
      "3328\n",
      "3344\n",
      "3360\n",
      "3376\n",
      "3392\n",
      "3408\n",
      "3424\n",
      "3440\n",
      "3456\n",
      "3472\n",
      "3488\n",
      "3504\n",
      "3520\n",
      "3536\n",
      "3552\n",
      "3568\n",
      "3584\n",
      "3600\n",
      "3616\n",
      "3632\n",
      "3648\n",
      "3664\n",
      "3680\n",
      "3696\n",
      "3712\n",
      "3728\n",
      "3744\n",
      "3760\n",
      "3776\n",
      "3792\n",
      "3808\n",
      "3824\n",
      "3840\n",
      "3856\n",
      "3872\n",
      "3888\n",
      "3904\n",
      "3920\n",
      "3936\n",
      "3952\n",
      "3968\n",
      "3984\n",
      "4000\n",
      "4016\n",
      "4032\n",
      "4048\n",
      "4064\n",
      "4080\n",
      "4096\n",
      "4112\n",
      "4128\n",
      "4144\n",
      "4160\n",
      "4176\n",
      "4192\n",
      "4208\n",
      "4224\n",
      "4240\n",
      "4256\n",
      "4272\n",
      "4288\n",
      "4304\n",
      "4320\n",
      "4336\n",
      "4352\n",
      "4368\n",
      "4384\n",
      "4400\n",
      "4416\n",
      "4432\n",
      "4448\n",
      "4464\n",
      "4480\n",
      "4496\n",
      "4512\n",
      "4528\n",
      "4544\n",
      "4560\n",
      "4576\n",
      "4592\n",
      "4608\n",
      "4624\n",
      "4640\n",
      "4656\n",
      "4672\n",
      "4688\n",
      "4704\n",
      "4720\n",
      "4736\n",
      "4752\n",
      "4768\n",
      "4784\n",
      "4800\n",
      "4816\n",
      "4832\n",
      "4848\n",
      "4864\n",
      "4880\n",
      "4896\n",
      "4912\n",
      "4928\n",
      "4944\n",
      "4960\n",
      "4976\n",
      "4992\n",
      "5008\n",
      "5024\n",
      "5040\n",
      "5056\n",
      "5072\n",
      "5088\n",
      "5104\n",
      "5120\n",
      "5136\n",
      "5152\n",
      "5168\n",
      "5184\n",
      "5200\n",
      "5216\n",
      "5232\n",
      "5248\n",
      "5264\n",
      "5280\n",
      "5296\n",
      "5312\n",
      "5328\n",
      "5344\n",
      "5360\n",
      "5376\n",
      "5392\n",
      "5408\n",
      "5424\n",
      "5440\n",
      "5456\n",
      "5472\n",
      "5488\n",
      "5504\n",
      "5520\n",
      "5536\n",
      "5552\n",
      "5568\n",
      "5584\n",
      "5600\n",
      "5616\n",
      "5632\n",
      "5648\n",
      "5664\n",
      "5680\n",
      "5696\n",
      "5712\n",
      "5728\n",
      "5744\n",
      "5760\n",
      "5776\n",
      "5792\n",
      "5808\n",
      "5824\n",
      "5840\n",
      "5856\n",
      "5872\n",
      "5888\n",
      "5904\n",
      "5920\n",
      "5936\n",
      "5952\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat -P data/\n",
    "data = {}\n",
    "df = pd.DataFrame({})\n",
    "\n",
    "with open('data/credit_card.dat', 'rb') as file:\n",
    "    file_content = file.read()\n",
    "    word_counter = 0\n",
    "    #each line : we read a word of 8 bytes\n",
    "    for i in range(0, len(file_content), 16):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
